![[Pasted image 20250430151202.png]]I hvilken grad bør autonome våpen kunne ta beslutninger om liv og død

Kantiansk pliktetikk

Siden KI- verken har moralsk eller etisk kompass vil dette bryte med både Universalitetsprinsippet og Humanitetsprinsippet og derfor vil en pliktetiker tenke at Kunstlig intelligens ikke bør ha noe med liv of død ¨gjøre

Utilitarisme: 
Konsekvensetikk

![[Pasted image 20250430151621.png]]

Fra en utilitarists synsounkt vil spørsmålet dreie seg om konsekvensene i større grad enn det humianitære bildet

Autonome våpen er svært presise kilder => færre soldater døde og færre sivilister døde. 
Mulig bikonsekvens kan være at siden de er såpass mer presise vil man kunne angripe hyppigere siden det ikke påvirker sivil befolkning i samme grad som tradisjonell krig (gitt at man følger krigsregler)

Mulig motargumenter
